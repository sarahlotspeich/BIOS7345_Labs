---
title: "BIOS7345 Lab 7"
subtitle: "Factor coding schemes"
author: "Sarah Lotspeich"
date: "2 November 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, tidy = TRUE)

#Load packages
library(rms)
library(ggplot2)
library(magrittr)
library(gmodels)
library(dplyr)
```

#Introduction
We are interested in comparing the `grades` of students in 3 different mathematics `classes`. A sample of 30 students is obtained.

```{r}
n <- 30 #number of students
grades <- rnorm(n, 75, 5)
classes <- sample(c("Class A", "Class B", "Class C"), n, replace = TRUE) %>% factor(levels = c("Class A", "Class B", "Class C"))
```

Begin by finding the overall mean grade across all classes 

```{r}
mean(grades)
```

as well as the mean grade in each class

```{r}
aggregate(grades ~ classes, FUN = mean)
```

Before we begin, a [helpful lil page](https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/) on factor coding schemes.

#Model 1: Reference cell coding
Reference cell coding is what we commonly refer to as "dummy variable coding". Since we have $k = 3$ levels of the `classes` variable, how many indicator variables will we need? 

There are three levels to the unordered factor variable `classes`

```{r}
table(classes)
```

so we will have 3 - 1 = 2 contrasts.

##Fit the model
```{r}
options(contrasts = c("contr.treatment", "contr.poly"))
mod <- lm(grades ~ classes)
summary(mod)
```

What does your $\pmb{\beta}$ vector look like for this model? 

$$\pmb{\beta} = \begin{bmatrix}\beta_0 \\ \beta_1 \\ \beta_2\end{bmatrix}$$

##Design matrix
Obtain the design matrix for this coding scheme (ignoring replicates) from your  `mod` object.  

```{r}
#save the unique rows of your design matrix
X = unique(model.matrix(mod))
X
```

Stop and think: which group is your reference group? 

\begin{quote}
The reference group is identified as that for which all indicator variables are equal to 0. In our case, if we assume that the first row is Class A then Class A is our reference group. 
\end{quote}

##Group means
We can obtain the class-specific means from the model parameter estimates by multiplying the unique rows of the design matrix (`X`) by the coefficients. 

```{r}
X %*% mod$coefficients
```

How do these means compare to those we calculated initially using `aggregate()`? 

\begin{quote}
The values are the same, but the design matrix outputted by the model has the reference group in the last row (whereas we had it in the first). 
\end{quote}

So what does this mean? When using reference cell coding, we have 

  1.  $\bar{X}_1 = \hat{\beta}_0$ (reference group)
  2.  $\bar{X}_2 = \hat{\beta}_0 + \hat{\beta}_1$ (first level)
  3.  $\bar{X}_3 = \hat{\beta}_0 + \hat{\beta}_3$ (second level)
  
If we knew the true mean grades in each class ($\mu_A, \mu_B, \mu_C$, respectively), how could we obtain the model parameters directly? 

  1.  $\beta_0 = \mu_A$: average grade in the reference group (Class A)
  2.  $\beta_1 = \mu_B - \mu_A$: difference in average grades of Classes B and A
  3.  $\beta_2 = \mu_C - \mu_A$: difference in average grades of Classes C and A
  
#Model 2: deviation coding
Whereas reference cell coding compared each level to a reference level, deviation coding compares each level to a grand mean. 

##Fit the model
```{r}
options(contrasts = c("contr.sum", "contr.poly"))
mod <- lm(grades ~ classes)
summary(mod)
```

What does your $\pmb{\beta}$ vector look like for this model? 

$$\pmb{\beta} = \begin{bmatrix}\mu \\ \alpha_1 \\ \alpha_2\end{bmatrix}$$
Here, $\mu$ is the \underline{grand mean}... but what's the grand mean anyway? 

```{r}
#is it the overall mean? 
mean(grades)

#or is it the mean of the means of the dependent variable at all levels of the factor
class_means <- aggregate(grades ~ classes, FUN = mean) %>% data.frame()
mean(class_means$grades)
```

##Design matrix
Obtain the design matrix for this coding scheme (ignoring replicates) from your  `mod` object.

```{r}
#save the unique rows of your design matrix
X = unique(model.matrix(mod))
X
```

How do we interpret the rows of `X`? 

  1.  Class A is compared to all others
  2.  Class B is compared to all others
  3.  Class C is never compared to the other levels (because we obtain information about it from rows 1-2)

##Group means
We can obtain the class-specific means from the model parameter estimates by multiplying the unique rows of the design matrix (`X`) by the coefficients. 

```{r}
X %*% mod$coefficients
```

How do these means compare to those we calculated initially using `aggregate()`? 

\begin{quote}
Still the same.
\end{quote}

So what does this mean? When using deviation coding, we have 

  1.  $\bar{X}_1 = \hat{\mu} + \hat{\alpha}_1$
  2.  $\bar{X}_2 = \hat{\mu} + \hat{\alpha}_2$
  3.  $\bar{X}_3 = \hat{\mu} - \hat{\alpha}_1 - \hat{\alpha}_2$
  
If we knew the true mean grades in each class ($\mu_A, \mu_B, \mu_C$, respectively) and the true grand mean ($\bar{\mu}$), how could we obtain the model parameters directly? 

  1.  $\mu = \bar{\mu}$: the mean of the class-specific mean grades
  2.  $\alpha_1 = \mu_1 - \bar{\mu}$: deviation of Class A's mean grade from the grand mean grade
  3.  $\alpha_2 = \mu_2 - \bar{\mu}$: deviation of Class B's mean grade from the grand mean grade
  
#Model 3: Helmert coding
Whereas reference cell coding compared each level to a reference level and deviation coding compares each level to a grand mean, Helmert coding compares each level with the mean of the subsequent levels. 

##Fit the model
```{r}
options(contrasts = c("contr.helmert", "contr.poly"))
mod <- lm(grades ~ classes)
summary(mod)
```

What does your $\pmb{\beta}$ vector look like for this model? 

$$\pmb{\beta} = \begin{bmatrix}\beta_0 \\ \beta_1 \\ \beta_2\end{bmatrix}$$

##Design matrix
Obtain the design matrix for this coding scheme (ignoring replicates) from your  `mod` object.

```{r}
#save the unique rows of your design matrix
X = unique(model.matrix(mod))
X
```

How do we interpret the rows of `X`? 

  1.  Class A is compared to Classes B and C
  2.  Class B is compared to Class C
  3.  Class C is never compared to the other levels (because we obtain information about it from rows 1-2)

##Group means
We can obtain the class-specific means from the model parameter estimates by multiplying the unique rows of the design matrix (`X`) by the coefficients. 

```{r}
X %*% mod$coefficients
```

How do these means compare to those we calculated initially using `aggregate()`? 

\begin{quote}
Still the same.
\end{quote}

So what does this mean? When using deviation coding, we have 

  1.  $\bar{X}_1 = \hat{\beta}_0 - \hat{\beta}_1 - \hat{\beta}_2$
  2.  $\bar{X}_2 = \hat{\beta_0} + \hat{\beta_1} - \hat{\beta}_2$
  3.  $\bar{X}_3 = \hat{\beta}_0 + 2\hat{\beta}_2$
  
If we knew the true mean grades in each class ($\mu_A, \mu_B, \mu_C$, respectively) and the true grand mean ($\bar{\mu}$), how could we obtain the model parameters directly? Interpret.

  1.  $\beta_0 = \bar{\mu}$: the mean of the class-specific mean grades
  2.  $\beta_1 = \frac{1}{2}(\mu_2 - \mu_1)$: the average difference between the means of Classes A and B
  3.  $\beta_2 = \frac{1}{3}(\mu_3 - \frac{1}{2}(\mu_2 - \mu_1)) = \frac{1}{3}(\mu_3 - \beta_1)$: the average difference between the mean of Class C and the average difference between the means of Classes A and B